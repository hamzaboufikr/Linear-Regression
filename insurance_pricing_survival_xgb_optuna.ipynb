{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69efda9",
   "metadata": {},
   "source": [
    "\n",
    "# Insurance Pricing, Survival Analysis & XGBoost Tuning (Optuna)\n",
    "\n",
    "This notebook demonstrates an end‑to‑end workflow on the classical **`insurance.csv`** dataset:\n",
    "\n",
    "1. **Data loading & basic exploration**\n",
    "2. **Pricing models**\n",
    "   - Generalized Linear Model (**GLM**) with a **Tweedie** family\n",
    "   - **Generalized Additive Model (GAM)** for nonlinear pricing effects\n",
    "3. **Survival analysis**\n",
    "   - **Kaplan–Meier** curves\n",
    "   - **Cox proportional hazards** model\n",
    "4. **XGBoost regression** for claim cost with **hyperparameter tuning using Optuna**\n",
    "\n",
    "> ⚠️ **Note**: Adjust column names/paths if your file differs from the classic `insurance.csv` (age, sex, bmi, children, smoker, region, charges).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd6a93",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b099935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the dataset (put insurance.csv in the same folder as this notebook)\n",
    "DATA_PATH = \"insurance.csv\"  # change this if needed\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b110ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick visualization: distribution of charges and some relationships\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"charges\"], bins=40)\n",
    "plt.title(\"Distribution of Charges\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data=df, x=\"age\", y=\"charges\", hue=\"smoker\")\n",
    "plt.title(\"Charges vs Age by Smoker Status\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccffe72",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Pricing Models\n",
    "\n",
    "We will build pricing models with:\n",
    "\n",
    "- **GLM with Tweedie family** (compound Poisson–Gamma, useful for claim severity/frequency)\n",
    "- **GAM (pyGAM)** to capture nonlinear effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target: charges (claim cost / premium)\n",
    "y = df[\"charges\"]\n",
    "\n",
    "# Features: all except charges\n",
    "X = df.drop(columns=[\"charges\"])\n",
    "\n",
    "# One‑hot encode categorical features for the GLM and tree-based models\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "X_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df6060",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 GLM with Tweedie Family (using `statsmodels`)\n",
    "\n",
    "We model charges using a Tweedie distribution with a **log link**, suitable for positive, right‑skewed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d169216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Tweedie\n",
    "\n",
    "X_glm = sm.add_constant(X_encoded)  # add intercept\n",
    "y_glm = y\n",
    "\n",
    "glm_model = sm.GLM(\n",
    "    y_glm,\n",
    "    X_glm,\n",
    "    family=sm.families.Tweedie(\n",
    "        var_power=1.5,             # 1 < p < 2 → compound Poisson–Gamma\n",
    "        link=sm.families.links.log()\n",
    "    )\n",
    ")\n",
    "\n",
    "glm_res = glm_model.fit()\n",
    "print(glm_res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a46003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicted vs actual from GLM\n",
    "y_pred_glm = glm_res.predict(X_glm)\n",
    "\n",
    "rmse_glm = mean_squared_error(y, y_pred_glm, squared=False)\n",
    "r2_glm = r2_score(y, y_pred_glm)\n",
    "print(f\"GLM Tweedie RMSE: {rmse_glm:,.2f}\")\n",
    "print(f\"GLM Tweedie R²:   {r2_glm:,.3f}\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y, y_pred_glm, alpha=0.4)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], \"r--\")\n",
    "plt.xlabel(\"Actual charges\")\n",
    "plt.ylabel(\"Predicted charges (GLM Tweedie)\")\n",
    "plt.title(\"Actual vs Predicted Charges (GLM Tweedie)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c13dc",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Generalized Additive Model (GAM) using `pyGAM`\n",
    "\n",
    "We fit a GAM to allow smooth nonlinear effects for all predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff478d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install pyGAM if not already installed (uncomment the next line when running locally)\n",
    "# %pip install pygam\n",
    "\n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "# We'll reuse X_encoded (all numeric after one‑hot encoding)\n",
    "X_gam = X_encoded.copy()\n",
    "y_gam = y.values\n",
    "\n",
    "# Build a GAM with a spline term s(i) for each feature\n",
    "terms = sum([s(i) for i in range(X_gam.shape[1])])\n",
    "gam = LinearGAM(terms)\n",
    "\n",
    "gam.gridsearch(X_gam.values, y_gam)\n",
    "print(gam.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate GAM\n",
    "y_pred_gam = gam.predict(X_gam.values)\n",
    "rmse_gam = mean_squared_error(y_gam, y_pred_gam, squared=False)\n",
    "r2_gam = r2_score(y_gam, y_pred_gam)\n",
    "print(f\"GAM RMSE: {rmse_gam:,.2f}\")\n",
    "print(f\"GAM R²:   {r2_gam:,.3f}\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_gam, y_pred_gam, alpha=0.4)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], \"r--\")\n",
    "plt.xlabel(\"Actual charges\")\n",
    "plt.ylabel(\"Predicted charges (GAM)\")\n",
    "plt.title(\"Actual vs Predicted Charges (GAM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot partial dependence for a few key features\n",
    "feature_names = X_gam.columns.tolist()\n",
    "\n",
    "for idx in [feature_names.index(col) for col in [\"age\", \"bmi\"] if col in feature_names]:\n",
    "    XX = gam.generate_X_grid(term=idx)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(XX[:, idx], gam.partial_dependence(term=idx, X=XX))\n",
    "    plt.plot(XX[:, idx], gam.partial_dependence(term=idx, X=XX, width=0.95)[1], linestyle=\"--\")\n",
    "    plt.title(f\"Partial dependence for {feature_names[idx]}\")\n",
    "    plt.xlabel(feature_names[idx])\n",
    "    plt.ylabel(\"Effect on charges\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d56e8",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Survival Analysis (Kaplan–Meier & Cox)\n",
    "\n",
    "The original `insurance.csv` does **not** contain time‑to‑event and censoring information.\n",
    "To illustrate survival models, we will **simulate** a survival dataset based on age and smoker status.\n",
    "\n",
    "In a real life insurance application, you would replace this simulated part with your true:\n",
    "- `duration` (time to death / lapse / claim)\n",
    "- `event` indicator (1 if event occurred, 0 if censored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ff8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install lifelines if not already installed (uncomment when running locally)\n",
    "# %pip install lifelines\n",
    "\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "\n",
    "surv_df = df.copy()\n",
    "\n",
    "# Simulate survival times (purely illustrative)\n",
    "# Hazard increases with age and smoker status\n",
    "baseline_hazard = 0.02\n",
    "age_effect = 0.04\n",
    "smoker_effect = 0.8\n",
    "\n",
    "lambda_rate = baseline_hazard * np.exp(\n",
    "    age_effect * (surv_df[\"age\"] - surv_df[\"age\"].mean()) / surv_df[\"age\"].std()\n",
    "    + smoker_effect * (surv_df[\"smoker\"] == \"yes\").astype(int)\n",
    ")\n",
    "\n",
    "surv_df[\"time\"] = np.random.exponential(1 / lambda_rate)\n",
    "surv_df[\"event\"] = np.random.binomial(1, 0.7, size=len(surv_df))  # 70% observed events\n",
    "\n",
    "surv_df[[\"age\", \"smoker\", \"time\", \"event\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd625c",
   "metadata": {},
   "source": [
    "### 3.1 Kaplan–Meier Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd745882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "kmf.fit(durations=surv_df[\"time\"], event_observed=surv_df[\"event\"], label=\"All\")\n",
    "kmf.plot_survival_function()\n",
    "plt.title(\"Kaplan–Meier Survival Curve (All)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Separate curves for smokers vs non‑smokers\n",
    "plt.figure(figsize=(6,4))\n",
    "for group_value, group_df in surv_df.groupby(\"smoker\"):\n",
    "    kmf.fit(group_df[\"time\"], group_df[\"event\"], label=f\"smoker={group_value}\")\n",
    "    kmf.plot_survival_function()\n",
    "\n",
    "plt.title(\"Kaplan–Meier by Smoker Status\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1342d",
   "metadata": {},
   "source": [
    "### 3.2 Cox Proportional Hazards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10427a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a Cox model dataframe: duration, event + covariates\n",
    "cox_df = surv_df[[\"time\", \"event\", \"age\", \"bmi\", \"children\"]].copy()\n",
    "\n",
    "# Add one‑hot encoded categorical covariates\n",
    "cox_covars = pd.get_dummies(\n",
    "    surv_df[[\"sex\", \"smoker\", \"region\"]],\n",
    "    drop_first=True\n",
    ")\n",
    "cox_df = pd.concat([cox_df, cox_covars], axis=1)\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(cox_df, duration_col=\"time\", event_col=\"event\")\n",
    "cph.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Cox model coefficients\n",
    "cph.plot()\n",
    "plt.title(\"Cox Model Coefficients\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9a1ff",
   "metadata": {},
   "source": [
    "\n",
    "## 4. XGBoost Regression with Optuna Hyperparameter Tuning\n",
    "\n",
    "We use XGBoost to model `charges` and Optuna to search for good hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install xgboost and optuna if needed (uncomment when running locally)\n",
    "# %pip install xgboost optuna\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "# Reuse the encoded features\n",
    "X_reg = X_encoded.copy()\n",
    "y_reg = y.copy()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"auto\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 600),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=False)\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best hyperparameters:\")\n",
    "study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "best_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    tree_method=\"auto\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_xgb = best_model.predict(X_valid)\n",
    "\n",
    "rmse_xgb = mean_squared_error(y_valid, y_pred_xgb, squared=False)\n",
    "r2_xgb = r2_score(y_valid, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost (tuned) RMSE: {rmse_xgb:,.2f}\")\n",
    "print(f\"XGBoost (tuned) R²:   {r2_xgb:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, y_pred_xgb, alpha=0.4)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], \"r--\")\n",
    "plt.xlabel(\"Actual charges (validation)\")\n",
    "plt.ylabel(\"Predicted charges (XGBoost tuned)\")\n",
    "plt.title(\"Actual vs Predicted Charges (XGBoost + Optuna)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d621c",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Built a **GLM Tweedie** pricing model for insurance charges.\n",
    "- Fitted a **GAM** to capture nonlinear relationships.\n",
    "- Illustrated **survival analysis** with **Kaplan–Meier** and **Cox PH** models (using simulated durations).\n",
    "- Trained an **XGBoost** regressor and tuned hyperparameters with **Optuna**.\n",
    "\n",
    "You can adapt this structure to your own life insurance or non‑life datasets by:\n",
    "- Replacing `charges` with your claim or premium variable.\n",
    "- Providing real survival times (`duration`) and event indicators (`event`) for the survival analysis section.\n",
    "- Adding exposure offsets and frequency/severity decomposition as needed.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
